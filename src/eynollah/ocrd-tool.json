{
  "version": "0.5.0",
  "git_url": "https://github.com/qurator-spk/eynollah",
  "dockerhub": "ocrd/eynollah",
  "tools": {
    "ocrd-eynollah-segment": {
      "executable": "ocrd-eynollah-segment",
      "categories": ["Layout analysis"],
      "description": "Segment page into regions and lines and do reading order detection with eynollah",
      "input_file_grp_cardinality": 1,
      "output_file_grp_cardinality": 1,
      "steps": ["layout/segmentation/region", "layout/segmentation/line"],
      "parameters": {
        "models": {
          "type": "string",
          "format": "uri",
          "content-type": "text/directory",
          "cacheable": true,
          "description": "Directory containing models to be used (See https://qurator-data.de/eynollah)",
          "required": true
        },
        "dpi": {
          "type": "number",
          "format": "float",
          "description": "pixel density in dots per inch (overrides any meta-data in the images); ignored if <= 0 (with fall-back 230)",
          "default": 0
        },
        "full_layout": {
          "type": "boolean",
          "default": true,
          "description": "Try to detect all element subtypes, including drop-caps and headings"
        },
         "light_version": {
          "type": "boolean",
          "default": true,
          "description": "Try to detect all element subtypes in light version (faster+simpler method for main region detection and deskewing)"
        },
         "textline_light": {
          "type": "boolean",
          "default": true,
          "description": "Light version need textline light. If this parameter set to true, this tool will try to return contoure of textlines instead of rectangle bounding box of textline with a faster method."
        },
        "tables": {
          "type": "boolean",
          "default": false,
          "description": "Try to detect table regions"
        },
        "curved_line": {
          "type": "boolean",
          "default": false,
          "description": "try to return contour of textlines instead of just rectangle bounding box. Needs more processing time"
        },
        "ignore_page_extraction": {
          "type": "boolean",
          "default": false,
          "description": "if this parameter set to true, this tool would ignore page extraction"
        },
        "allow_scaling": {
          "type": "boolean",
          "default": false,
          "description": "check the resolution against the number of detected columns and if needed, scale the image up or down during layout detection (heuristic to improve quality and performance)"
        },
        "allow_enhancement": {
          "type": "boolean",
          "default": false,
          "description": "if this parameter set to true, this tool would check that input image need resizing and enhancement or not."
        },
        "right_to_left": {
          "type": "boolean",
          "default": false,
          "description": "if this parameter set to true, this tool will extract right-to-left reading order."
        },
        "headers_off": {
          "type": "boolean",
          "default": false,
          "description": "ignore the special role of headings during reading order detection"
        },
        "reading_order_machine_based": {
          "type": "boolean",
          "default": false,
          "description": "use data-driven (rather than rule-based) reading order detection"
        }
      },
      "resources": [
        {
          "url": "https://zenodo.org/records/17194824/files/models_layout_v0_5_0.tar.gz?download=1",
          "name": "models_layout_v0_5_0",
          "type": "archive",
          "path_in_archive": "models_layout_v0_5_0",
          "size": 3525684179,
          "description": "Models for layout detection, reading order detection, textline detection, page extraction, column classification, table detection, binarization, image enhancement",
          "version_range": ">= v0.5.0"
        },
        {
          "description": "models for eynollah (TensorFlow SavedModel format)",
          "url": "https://github.com/qurator-spk/eynollah/releases/download/v0.3.1/models_eynollah.tar.gz",
          "name": "default",
          "size": 1894627041,
          "type": "archive",
          "path_in_archive": "models_eynollah",
          "version_range": ">= v0.3.0, < v0.5.0"
        }
      ]
    },
    "ocrd-sbb-binarize": {
      "executable": "ocrd-sbb-binarize",
      "description": "Pixelwise binarization with selectional auto-encoders in Keras",
      "categories": ["Image preprocessing"],
      "steps": ["preprocessing/optimization/binarization"],
      "input_file_grp_cardinality": 1,
      "output_file_grp_cardinality": 1,
      "parameters": {
        "operation_level": {
          "type": "string",
          "enum": ["page", "region"],
          "default": "page",
          "description": "PAGE XML hierarchy level to operate on"
        },
        "model": {
          "description": "Directory containing HDF5 or SavedModel/ProtoBuf models. Can be an absolute path or a path relative to the OCR-D resource location, the current working directory or the $SBB_BINARIZE_DATA environment variable (if set)",
          "type": "string",
          "format": "uri",
          "content-type": "text/directory",
          "required": true
        }
      },
      "resources": [
        {
          "url": "https://github.com/qurator-spk/sbb_binarization/releases/download/v0.0.11/saved_model_2020_01_16.zip",
          "name": "default",
          "type": "archive",
          "path_in_archive": "saved_model_2020_01_16",
          "size": 563147331,
          "description": "default models provided by github.com/qurator-spk (SavedModel format)"
        },
        {
          "url": "https://github.com/qurator-spk/sbb_binarization/releases/download/v0.0.11/saved_model_2021_03_09.zip",
          "name": "default-2021-03-09",
          "type": "archive",
          "path_in_archive": ".",
          "size": 133230419,
          "description": "updated default models provided by github.com/qurator-spk (SavedModel format)"
        }
      ]
    }
  }
}
